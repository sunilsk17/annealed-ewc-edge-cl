==========================================
ResNet-18 CIFAR-100 EXPERIMENTS
Running: λ=0, 200, 500, 1000, 2000, 5000 + Annealed
Start time: Fri Jan 30 17:27:42 IST 2026
Estimated: 4-5 hours
==========================================

[1/7] Training λ=0 (Baseline)...
/Users/sunilkumars/Desktop/EWC Project/drift_cl_edge/venv/lib/python3.13/site-packages/torchvision/datasets/cifar.py:83: VisibleDeprecationWarning: dtype(): align should be passed as Python or NumPy boolean but got `align=0`. Did you mean to pass a tuple to create a subarray type? (Deprecated NumPy 2.4)
  entry = pickle.load(f, encoding="latin1")
/Users/sunilkumars/Desktop/EWC Project/drift_cl_edge/venv/lib/python3.13/site-packages/torch/utils/data/dataloader.py:692: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, device pinned memory won't be used.
  warnings.warn(warn_msg)
Using device: mps
Training ResNet-18 on Split-CIFAR-100: 10 tasks, 10 epochs/task, λ=0.0
Split-CIFAR-100 initialized:
  Tasks: 10
  Classes per task: 10
  Class order: [83 53 70 45 44 39 22 80 10  0 18 30 73 33 90  4 76 77 12 31]... (first 20)
Task 0: Classes [83, 53, 70, 45, 44, 39, 22, 80, 10, 0]
  Train samples: 5000
  Test samples: 1000
Task 1: Classes [18, 30, 73, 33, 90, 4, 76, 77, 12, 31]
  Train samples: 5000
  Test samples: 1000
Task 2: Classes [55, 88, 26, 42, 69, 15, 40, 96, 9, 72]
  Train samples: 5000
  Test samples: 1000
Task 3: Classes [11, 47, 85, 28, 93, 5, 66, 65, 35, 16]
  Train samples: 5000
  Test samples: 1000
Task 4: Classes [49, 34, 7, 95, 27, 19, 81, 25, 62, 13]
  Train samples: 5000
  Test samples: 1000
Task 5: Classes [24, 3, 17, 38, 8, 78, 6, 64, 36, 89]
  Train samples: 5000
  Test samples: 1000
Task 6: Classes [56, 99, 54, 43, 50, 67, 46, 68, 61, 97]
  Train samples: 5000
  Test samples: 1000
Task 7: Classes [79, 41, 58, 48, 98, 57, 75, 32, 94, 59]
  Train samples: 5000
  Test samples: 1000
Task 8: Classes [63, 84, 37, 29, 1, 52, 21, 2, 23, 87]
  Train samples: 5000
  Test samples: 1000
Task 9: Classes [91, 74, 86, 82, 20, 60, 71, 14, 92, 51]
  Train samples: 5000
  Test samples: 1000

============================================================
Training on Task 0 (Classes: [83, 53, 70, 45, 44, 39, 22, 80, 10, 0])
============================================================
Epoch 1/10 - Loss: 1.8887 - Acc: 0.3638
Epoch 2/10 - Loss: 1.5071 - Acc: 0.4602
Epoch 3/10 - Loss: 1.3663 - Acc: 0.5178
Epoch 4/10 - Loss: 1.2436 - Acc: 0.5670
Epoch 5/10 - Loss: 1.1513 - Acc: 0.5902
Epoch 6/10 - Loss: 1.0452 - Acc: 0.6346
Epoch 7/10 - Loss: 0.9966 - Acc: 0.6488
Epoch 8/10 - Loss: 0.8297 - Acc: 0.7048
Epoch 9/10 - Loss: 0.6340 - Acc: 0.7692
Epoch 10/10 - Loss: 0.5734 - Acc: 0.7990
Saved: results_resnet_cifar100/lambda_sweep/lambda_0/model_task0.pt

============================================================
Training on Task 1 (Classes: [18, 30, 73, 33, 90, 4, 76, 77, 12, 31])
============================================================
Epoch 1/10 - Loss: 3.1302 - Acc: 0.2274
Epoch 2/10 - Loss: 1.4528 - Acc: 0.4636
Epoch 3/10 - Loss: 1.2534 - Acc: 0.5480
Epoch 4/10 - Loss: 1.0586 - Acc: 0.6186
Epoch 5/10 - Loss: 0.9370 - Acc: 0.6682
Epoch 6/10 - Loss: 0.8036 - Acc: 0.7156
Epoch 7/10 - Loss: 0.6152 - Acc: 0.7868
Epoch 8/10 - Loss: 0.5587 - Acc: 0.8018
Epoch 9/10 - Loss: 0.4936 - Acc: 0.8362
Epoch 10/10 - Loss: 0.5496 - Acc: 0.8210
Saved: results_resnet_cifar100/lambda_sweep/lambda_0/model_task1.pt

============================================================
Training on Task 2 (Classes: [55, 88, 26, 42, 69, 15, 40, 96, 9, 72])
============================================================
Epoch 1/10 - Loss: 4.9930 - Acc: 0.1310
Epoch 2/10 - Loss: 1.9791 - Acc: 0.2896
Epoch 3/10 - Loss: 1.6782 - Acc: 0.3884
Epoch 4/10 - Loss: 1.5233 - Acc: 0.4562
Epoch 5/10 - Loss: 1.3800 - Acc: 0.5114
Epoch 6/10 - Loss: 1.2447 - Acc: 0.5492
Epoch 7/10 - Loss: 1.1404 - Acc: 0.5898
Epoch 8/10 - Loss: 1.0717 - Acc: 0.6168
Epoch 9/10 - Loss: 0.9085 - Acc: 0.6838
Epoch 10/10 - Loss: 0.7978 - Acc: 0.7116
Saved: results_resnet_cifar100/lambda_sweep/lambda_0/model_task2.pt

============================================================
Training on Task 3 (Classes: [11, 47, 85, 28, 93, 5, 66, 65, 35, 16])
============================================================
Epoch 1/10 - Loss: 5.4989 - Acc: 0.0482
Epoch 2/10 - Loss: 2.3139 - Acc: 0.1464
Epoch 3/10 - Loss: 2.1884 - Acc: 0.2064
Epoch 4/10 - Loss: 2.0394 - Acc: 0.2692
Epoch 5/10 - Loss: 1.8134 - Acc: 0.3434
Epoch 6/10 - Loss: 1.6417 - Acc: 0.4220
Epoch 7/10 - Loss: 1.4900 - Acc: 0.4710
Epoch 8/10 - Loss: 1.2836 - Acc: 0.5380
Epoch 9/10 - Loss: 1.1157 - Acc: 0.6014
Epoch 10/10 - Loss: 1.0818 - Acc: 0.6184
Saved: results_resnet_cifar100/lambda_sweep/lambda_0/model_task3.pt

============================================================
Training on Task 4 (Classes: [49, 34, 7, 95, 27, 19, 81, 25, 62, 13])
============================================================
Epoch 1/10 - Loss: 6.0480 - Acc: 0.0076
Epoch 2/10 - Loss: 2.5156 - Acc: 0.1894
Epoch 3/10 - Loss: 1.8488 - Acc: 0.3326
Epoch 4/10 - Loss: 1.6421 - Acc: 0.4058
Epoch 5/10 - Loss: 1.4706 - Acc: 0.4646
Epoch 6/10 - Loss: 1.3112 - Acc: 0.5270
Epoch 7/10 - Loss: 1.2130 - Acc: 0.5512
Epoch 8/10 - Loss: 1.0451 - Acc: 0.6218
Epoch 9/10 - Loss: 0.9569 - Acc: 0.6636
Epoch 10/10 - Loss: 0.9325 - Acc: 0.6770
Saved: results_resnet_cifar100/lambda_sweep/lambda_0/model_task4.pt

============================================================
Training on Task 5 (Classes: [24, 3, 17, 38, 8, 78, 6, 64, 36, 89])
============================================================
Epoch 1/10 - Loss: 7.0728 - Acc: 0.0032
Epoch 2/10 - Loss: 3.5066 - Acc: 0.0744
Epoch 3/10 - Loss: 2.4275 - Acc: 0.1366
Epoch 4/10 - Loss: 2.2508 - Acc: 0.1720
Epoch 5/10 - Loss: 2.1282 - Acc: 0.2470
Epoch 6/10 - Loss: 2.0042 - Acc: 0.2816
Epoch 7/10 - Loss: 1.8621 - Acc: 0.3132
Epoch 8/10 - Loss: 1.7495 - Acc: 0.3702
Epoch 9/10 - Loss: 1.6001 - Acc: 0.4266
Epoch 10/10 - Loss: 1.5075 - Acc: 0.4598
Saved: results_resnet_cifar100/lambda_sweep/lambda_0/model_task5.pt

============================================================
Training on Task 6 (Classes: [56, 99, 54, 43, 50, 67, 46, 68, 61, 97])
============================================================
Epoch 1/10 - Loss: 7.7349 - Acc: 0.0018
Epoch 2/10 - Loss: 4.0641 - Acc: 0.0334
Epoch 3/10 - Loss: 2.7638 - Acc: 0.1346
Epoch 4/10 - Loss: 2.2974 - Acc: 0.1564
Epoch 5/10 - Loss: 2.1706 - Acc: 0.2238
Epoch 6/10 - Loss: 1.9589 - Acc: 0.3054
Epoch 7/10 - Loss: 1.8061 - Acc: 0.3534
Epoch 8/10 - Loss: 1.6681 - Acc: 0.3884
Epoch 9/10 - Loss: 1.6137 - Acc: 0.4260
Epoch 10/10 - Loss: 1.4779 - Acc: 0.4672
Saved: results_resnet_cifar100/lambda_sweep/lambda_0/model_task6.pt

============================================================
Training on Task 7 (Classes: [79, 41, 58, 48, 98, 57, 75, 32, 94, 59])
============================================================
Epoch 1/10 - Loss: 7.6015 - Acc: 0.0028
Epoch 2/10 - Loss: 3.0923 - Acc: 0.0930
Epoch 3/10 - Loss: 2.3123 - Acc: 0.1664
Epoch 4/10 - Loss: 2.2004 - Acc: 0.2244
Epoch 5/10 - Loss: 1.9829 - Acc: 0.3022
Epoch 6/10 - Loss: 1.7688 - Acc: 0.3598
Epoch 7/10 - Loss: 1.5861 - Acc: 0.4240
Epoch 8/10 - Loss: 1.4753 - Acc: 0.4692
Epoch 9/10 - Loss: 1.2672 - Acc: 0.5636
Epoch 10/10 - Loss: 1.1699 - Acc: 0.5964
Saved: results_resnet_cifar100/lambda_sweep/lambda_0/model_task7.pt

============================================================
Training on Task 8 (Classes: [63, 84, 37, 29, 1, 52, 21, 2, 23, 87])
============================================================
Epoch 1/10 - Loss: 7.8362 - Acc: 0.0026
Epoch 2/10 - Loss: 2.4526 - Acc: 0.1474
Epoch 3/10 - Loss: 1.9947 - Acc: 0.3110
Epoch 4/10 - Loss: 1.5478 - Acc: 0.4454
Epoch 5/10 - Loss: 1.2993 - Acc: 0.5454
Epoch 6/10 - Loss: 1.0912 - Acc: 0.6234
Epoch 7/10 - Loss: 0.9362 - Acc: 0.6848
Epoch 8/10 - Loss: 0.9623 - Acc: 0.6718
Epoch 9/10 - Loss: 0.7607 - Acc: 0.7558
Epoch 10/10 - Loss: 0.7353 - Acc: 0.7720
Saved: results_resnet_cifar100/lambda_sweep/lambda_0/model_task8.pt

============================================================
Training on Task 9 (Classes: [91, 74, 86, 82, 20, 60, 71, 14, 92, 51])
============================================================
Epoch 1/10 - Loss: 6.6338 - Acc: 0.0424
Epoch 2/10 - Loss: 2.0816 - Acc: 0.2622
Epoch 3/10 - Loss: 1.5973 - Acc: 0.4212
Epoch 4/10 - Loss: 1.2577 - Acc: 0.5302
Epoch 5/10 - Loss: 1.1184 - Acc: 0.5856
Epoch 6/10 - Loss: 1.0298 - Acc: 0.6264
Epoch 7/10 - Loss: 0.9209 - Acc: 0.6596
Epoch 8/10 - Loss: 0.8057 - Acc: 0.7148
Epoch 9/10 - Loss: 0.7359 - Acc: 0.7410
Epoch 10/10 - Loss: 0.6637 - Acc: 0.7658
Saved: results_resnet_cifar100/lambda_sweep/lambda_0/model_task9.pt

============================================================
Training Complete!
============================================================
[1/7] Evaluating λ=0...
/Users/sunilkumars/Desktop/EWC Project/drift_cl_edge/venv/lib/python3.13/site-packages/torchvision/datasets/cifar.py:83: VisibleDeprecationWarning: dtype(): align should be passed as Python or NumPy boolean but got `align=0`. Did you mean to pass a tuple to create a subarray type? (Deprecated NumPy 2.4)
  entry = pickle.load(f, encoding="latin1")
Using device: mps
Split-CIFAR-100 initialized:
  Tasks: 10
  Classes per task: 10
  Class order: [83 53 70 45 44 39 22 80 10  0 18 30 73 33 90  4 76 77 12 31]... (first 20)
Task 0: Classes [83, 53, 70, 45, 44, 39, 22, 80, 10, 0]
  Train samples: 5000
  Test samples: 1000
Task 1: Classes [18, 30, 73, 33, 90, 4, 76, 77, 12, 31]
  Train samples: 5000
  Test samples: 1000
Task 2: Classes [55, 88, 26, 42, 69, 15, 40, 96, 9, 72]
  Train samples: 5000
  Test samples: 1000
Task 3: Classes [11, 47, 85, 28, 93, 5, 66, 65, 35, 16]
  Train samples: 5000
  Test samples: 1000
Task 4: Classes [49, 34, 7, 95, 27, 19, 81, 25, 62, 13]
  Train samples: 5000
  Test samples: 1000
Task 5: Classes [24, 3, 17, 38, 8, 78, 6, 64, 36, 89]
  Train samples: 5000
  Test samples: 1000
Task 6: Classes [56, 99, 54, 43, 50, 67, 46, 68, 61, 97]
  Train samples: 5000
  Test samples: 1000
Task 7: Classes [79, 41, 58, 48, 98, 57, 75, 32, 94, 59]
  Train samples: 5000
  Test samples: 1000
Task 8: Classes [63, 84, 37, 29, 1, 52, 21, 2, 23, 87]
  Train samples: 5000
  Test samples: 1000
Task 9: Classes [91, 74, 86, 82, 20, 60, 71, 14, 92, 51]
  Train samples: 5000
  Test samples: 1000
Task 0: Classes [83, 53, 70, 45, 44, 39, 22, 80, 10, 0]
  Train samples: 5000
  Test samples: 1000
Evaluating on Task 0 (Classes: [83, 53, 70, 45, 44, 39, 22, 80, 10, 0])...
Task 0 Accuracy: 0.0000
Task 1: Classes [18, 30, 73, 33, 90, 4, 76, 77, 12, 31]
  Train samples: 5000
  Test samples: 1000
Evaluating on Task 1 (Classes: [18, 30, 73, 33, 90, 4, 76, 77, 12, 31])...
Task 1 Accuracy: 0.0000
Task 2: Classes [55, 88, 26, 42, 69, 15, 40, 96, 9, 72]
  Train samples: 5000
  Test samples: 1000
Evaluating on Task 2 (Classes: [55, 88, 26, 42, 69, 15, 40, 96, 9, 72])...
Task 2 Accuracy: 0.0000
Task 3: Classes [11, 47, 85, 28, 93, 5, 66, 65, 35, 16]
  Train samples: 5000
  Test samples: 1000
Evaluating on Task 3 (Classes: [11, 47, 85, 28, 93, 5, 66, 65, 35, 16])...
Task 3 Accuracy: 0.0000
Task 4: Classes [49, 34, 7, 95, 27, 19, 81, 25, 62, 13]
  Train samples: 5000
  Test samples: 1000
Evaluating on Task 4 (Classes: [49, 34, 7, 95, 27, 19, 81, 25, 62, 13])...
Task 4 Accuracy: 0.0000
Task 5: Classes [24, 3, 17, 38, 8, 78, 6, 64, 36, 89]
  Train samples: 5000
  Test samples: 1000
Evaluating on Task 5 (Classes: [24, 3, 17, 38, 8, 78, 6, 64, 36, 89])...
Task 5 Accuracy: 0.0000
Task 6: Classes [56, 99, 54, 43, 50, 67, 46, 68, 61, 97]
  Train samples: 5000
  Test samples: 1000
Evaluating on Task 6 (Classes: [56, 99, 54, 43, 50, 67, 46, 68, 61, 97])...
Task 6 Accuracy: 0.0000
Task 7: Classes [79, 41, 58, 48, 98, 57, 75, 32, 94, 59]
  Train samples: 5000
  Test samples: 1000
Evaluating on Task 7 (Classes: [79, 41, 58, 48, 98, 57, 75, 32, 94, 59])...
Task 7 Accuracy: 0.0000
Task 8: Classes [63, 84, 37, 29, 1, 52, 21, 2, 23, 87]
  Train samples: 5000
  Test samples: 1000
Evaluating on Task 8 (Classes: [63, 84, 37, 29, 1, 52, 21, 2, 23, 87])...
Task 8 Accuracy: 0.0000
Task 9: Classes [91, 74, 86, 82, 20, 60, 71, 14, 92, 51]
  Train samples: 5000
  Test samples: 1000
Evaluating on Task 9 (Classes: [91, 74, 86, 82, 20, 60, 71, 14, 92, 51])...
Task 9 Accuracy: 0.7280

============================================================
Final Accuracies: ['0.0000', '0.0000', '0.0000', '0.0000', '0.0000', '0.0000', '0.0000', '0.0000', '0.0000', '0.7280']
Average Accuracy: 0.0728
Final Task: 0.7280
Early Tasks Avg: 0.0000
============================================================
Results saved to results_resnet_cifar100/lambda_sweep/lambda_0_results.json

[2/7] Training λ=200...
/Users/sunilkumars/Desktop/EWC Project/drift_cl_edge/venv/lib/python3.13/site-packages/torchvision/datasets/cifar.py:83: VisibleDeprecationWarning: dtype(): align should be passed as Python or NumPy boolean but got `align=0`. Did you mean to pass a tuple to create a subarray type? (Deprecated NumPy 2.4)
  entry = pickle.load(f, encoding="latin1")
/Users/sunilkumars/Desktop/EWC Project/drift_cl_edge/venv/lib/python3.13/site-packages/torch/utils/data/dataloader.py:692: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, device pinned memory won't be used.
  warnings.warn(warn_msg)
Using device: mps
Training ResNet-18 on Split-CIFAR-100: 10 tasks, 10 epochs/task, λ=200.0
Split-CIFAR-100 initialized:
  Tasks: 10
  Classes per task: 10
  Class order: [83 53 70 45 44 39 22 80 10  0 18 30 73 33 90  4 76 77 12 31]... (first 20)
Task 0: Classes [83, 53, 70, 45, 44, 39, 22, 80, 10, 0]
  Train samples: 5000
  Test samples: 1000
Task 1: Classes [18, 30, 73, 33, 90, 4, 76, 77, 12, 31]
  Train samples: 5000
  Test samples: 1000
Task 2: Classes [55, 88, 26, 42, 69, 15, 40, 96, 9, 72]
  Train samples: 5000
  Test samples: 1000
Task 3: Classes [11, 47, 85, 28, 93, 5, 66, 65, 35, 16]
  Train samples: 5000
  Test samples: 1000
Task 4: Classes [49, 34, 7, 95, 27, 19, 81, 25, 62, 13]
  Train samples: 5000
  Test samples: 1000
Task 5: Classes [24, 3, 17, 38, 8, 78, 6, 64, 36, 89]
  Train samples: 5000
  Test samples: 1000
Task 6: Classes [56, 99, 54, 43, 50, 67, 46, 68, 61, 97]
  Train samples: 5000
  Test samples: 1000
Task 7: Classes [79, 41, 58, 48, 98, 57, 75, 32, 94, 59]
  Train samples: 5000
  Test samples: 1000
Task 8: Classes [63, 84, 37, 29, 1, 52, 21, 2, 23, 87]
  Train samples: 5000
  Test samples: 1000
Task 9: Classes [91, 74, 86, 82, 20, 60, 71, 14, 92, 51]
  Train samples: 5000
  Test samples: 1000

============================================================
Training on Task 0 (Classes: [83, 53, 70, 45, 44, 39, 22, 80, 10, 0])
============================================================
Epoch 1/10 - Loss: 1.9137 - Acc: 0.3514
Epoch 2/10 - Loss: 1.4288 - Acc: 0.4852
Epoch 3/10 - Loss: 1.2488 - Acc: 0.5600
Epoch 4/10 - Loss: 1.1671 - Acc: 0.5938
Epoch 5/10 - Loss: 0.9285 - Acc: 0.6816
Epoch 6/10 - Loss: 0.8947 - Acc: 0.6780
Epoch 7/10 - Loss: 0.7039 - Acc: 0.7494
Epoch 8/10 - Loss: 0.5250 - Acc: 0.8166
Epoch 9/10 - Loss: 0.4005 - Acc: 0.8560
Epoch 10/10 - Loss: 0.3907 - Acc: 0.8620
Saved: results_resnet_cifar100/lambda_sweep/lambda_200/model_task0.pt
Computing Fisher for Task 0...
Computing Fisher Matrix...
Fisher Matrix computed.

============================================================
Training on Task 1 (Classes: [18, 30, 73, 33, 90, 4, 76, 77, 12, 31])
============================================================
Epoch 1/10 - Loss: 3.0812 - Acc: 0.3138
Epoch 2/10 - Loss: 1.3703 - Acc: 0.5534
Epoch 3/10 - Loss: 1.0474 - Acc: 0.6750
Epoch 4/10 - Loss: 0.8498 - Acc: 0.7426
Epoch 5/10 - Loss: 0.6468 - Acc: 0.8284
Epoch 6/10 - Loss: 0.7877 - Acc: 0.7790
Epoch 7/10 - Loss: 0.5606 - Acc: 0.8648
Epoch 8/10 - Loss: 0.4641 - Acc: 0.9114
Epoch 9/10 - Loss: 0.5126 - Acc: 0.8968
Epoch 10/10 - Loss: 0.4026 - Acc: 0.9414
Saved: results_resnet_cifar100/lambda_sweep/lambda_200/model_task1.pt
Computing Fisher for Task 1...
Computing Fisher Matrix...
Fisher Matrix computed.

============================================================
Training on Task 2 (Classes: [55, 88, 26, 42, 69, 15, 40, 96, 9, 72])
============================================================
Epoch 1/10 - Loss: 5.3542 - Acc: 0.2016
Epoch 2/10 - Loss: 1.9458 - Acc: 0.4406
Epoch 3/10 - Loss: 1.5777 - Acc: 0.5594
Epoch 4/10 - Loss: 1.2438 - Acc: 0.6702
Epoch 5/10 - Loss: 1.1452 - Acc: 0.7156
Epoch 6/10 - Loss: 1.0216 - Acc: 0.7714
Epoch 7/10 - Loss: 1.0171 - Acc: 0.7880
Epoch 8/10 - Loss: 0.7841 - Acc: 0.8810
Epoch 9/10 - Loss: 0.6288 - Acc: 0.9282
Epoch 10/10 - Loss: 0.5075 - Acc: 0.9732
Saved: results_resnet_cifar100/lambda_sweep/lambda_200/model_task2.pt
Computing Fisher for Task 2...
Computing Fisher Matrix...
Fisher Matrix computed.

============================================================
Training on Task 3 (Classes: [11, 47, 85, 28, 93, 5, 66, 65, 35, 16])
============================================================
Epoch 1/10 - Loss: 7.0417 - Acc: 0.0872
Epoch 2/10 - Loss: 2.7701 - Acc: 0.2560
Epoch 3/10 - Loss: 2.0900 - Acc: 0.4636
Epoch 4/10 - Loss: 1.6453 - Acc: 0.6180
Epoch 5/10 - Loss: 1.4808 - Acc: 0.6800
Epoch 6/10 - Loss: 1.2150 - Acc: 0.7798
Epoch 7/10 - Loss: 1.2585 - Acc: 0.8004
Epoch 8/10 - Loss: 1.2813 - Acc: 0.8134
Epoch 9/10 - Loss: 1.1360 - Acc: 0.8666
Epoch 10/10 - Loss: 1.1827 - Acc: 0.8766
Saved: results_resnet_cifar100/lambda_sweep/lambda_200/model_task3.pt
Computing Fisher for Task 3...
Computing Fisher Matrix...
Fisher Matrix computed.

============================================================
Training on Task 4 (Classes: [49, 34, 7, 95, 27, 19, 81, 25, 62, 13])
============================================================
Epoch 1/10 - Loss: 9.1903 - Acc: 0.1022
Epoch 2/10 - Loss: 3.4124 - Acc: 0.2944
Epoch 3/10 - Loss: 2.5750 - Acc: 0.4520
Epoch 4/10 - Loss: 2.0634 - Acc: 0.6068
Epoch 5/10 - Loss: 1.8655 - Acc: 0.6776
Epoch 6/10 - Loss: 1.6840 - Acc: 0.7598
Epoch 7/10 - Loss: 1.6869 - Acc: 0.8058
Epoch 8/10 - Loss: 1.5637 - Acc: 0.8478
Epoch 9/10 - Loss: 1.6946 - Acc: 0.8590
Epoch 10/10 - Loss: 2.0211 - Acc: 0.8236
Saved: results_resnet_cifar100/lambda_sweep/lambda_200/model_task4.pt
Computing Fisher for Task 4...
Computing Fisher Matrix...
Fisher Matrix computed.

============================================================
Training on Task 5 (Classes: [24, 3, 17, 38, 8, 78, 6, 64, 36, 89])
============================================================
Epoch 1/10 - Loss: 10.2219 - Acc: 0.0302
Epoch 2/10 - Loss: 4.0824 - Acc: 0.2140
Epoch 3/10 - Loss: 3.1553 - Acc: 0.3522
Epoch 4/10 - Loss: 2.5234 - Acc: 0.5216
Epoch 5/10 - Loss: 2.1685 - Acc: 0.6700
Epoch 6/10 - Loss: 2.0732 - Acc: 0.7622
Epoch 7/10 - Loss: 1.8768 - Acc: 0.8426
Epoch 8/10 - Loss: 2.2743 - Acc: 0.8120
Epoch 9/10 - Loss: 1.9892 - Acc: 0.8848
Epoch 10/10 - Loss: 2.6190 - Acc: 0.8316
Saved: results_resnet_cifar100/lambda_sweep/lambda_200/model_task5.pt
Computing Fisher for Task 5...
Computing Fisher Matrix...
Fisher Matrix computed.

============================================================
Training on Task 6 (Classes: [56, 99, 54, 43, 50, 67, 46, 68, 61, 97])
============================================================
Epoch 1/10 - Loss: 13.2274 - Acc: 0.0196
Epoch 2/10 - Loss: 5.1022 - Acc: 0.1806
Epoch 3/10 - Loss: 3.6600 - Acc: 0.3640
Epoch 4/10 - Loss: 2.9416 - Acc: 0.5944
Epoch 5/10 - Loss: 2.5812 - Acc: 0.7146
Epoch 6/10 - Loss: 2.6490 - Acc: 0.7592
Epoch 7/10 - Loss: 2.4081 - Acc: 0.8260
Epoch 8/10 - Loss: 2.2273 - Acc: 0.8842
Epoch 9/10 - Loss: 3.4204 - Acc: 0.7826
Epoch 10/10 - Loss: 2.6053 - Acc: 0.8742
Saved: results_resnet_cifar100/lambda_sweep/lambda_200/model_task6.pt
Computing Fisher for Task 6...
Computing Fisher Matrix...
Fisher Matrix computed.

============================================================
Training on Task 7 (Classes: [79, 41, 58, 48, 98, 57, 75, 32, 94, 59])
============================================================
Epoch 1/10 - Loss: 13.9322 - Acc: 0.0046
Epoch 2/10 - Loss: 6.0423 - Acc: 0.1430
Epoch 3/10 - Loss: 3.8460 - Acc: 0.4188
Epoch 4/10 - Loss: 2.9865 - Acc: 0.6848
Epoch 5/10 - Loss: 2.6613 - Acc: 0.7968
Epoch 6/10 - Loss: 2.5309 - Acc: 0.8664
Epoch 7/10 - Loss: 2.7225 - Acc: 0.8676
Epoch 8/10 - Loss: 2.5807 - Acc: 0.8916
Epoch 9/10 - Loss: 2.4134 - Acc: 0.9200
Epoch 10/10 - Loss: 2.9089 - Acc: 0.8802
Saved: results_resnet_cifar100/lambda_sweep/lambda_200/model_task7.pt
Computing Fisher for Task 7...
Computing Fisher Matrix...
Fisher Matrix computed.

============================================================
Training on Task 8 (Classes: [63, 84, 37, 29, 1, 52, 21, 2, 23, 87])
============================================================
Epoch 1/10 - Loss: 15.2660 - Acc: 0.0000
Epoch 2/10 - Loss: 7.8293 - Acc: 0.0232
Epoch 3/10 - Loss: 5.2194 - Acc: 0.1702
Epoch 4/10 - Loss: 4.1403 - Acc: 0.3720
Epoch 5/10 - Loss: 3.2168 - Acc: 0.6424
Epoch 6/10 - Loss: 2.8227 - Acc: 0.7734
Epoch 7/10 - Loss: 2.6970 - Acc: 0.8270
Epoch 8/10 - Loss: 2.7035 - Acc: 0.8492
Epoch 9/10 - Loss: 2.7581 - Acc: 0.8670
Epoch 10/10 - Loss: 2.4124 - Acc: 0.9152
Saved: results_resnet_cifar100/lambda_sweep/lambda_200/model_task8.pt
Computing Fisher for Task 8...
Computing Fisher Matrix...
Fisher Matrix computed.

============================================================
Training on Task 9 (Classes: [91, 74, 86, 82, 20, 60, 71, 14, 92, 51])
============================================================
Epoch 1/10 - Loss: 14.8333 - Acc: 0.0000
Epoch 2/10 - Loss: 8.3468 - Acc: 0.0174
Epoch 3/10 - Loss: 7.8193 - Acc: 0.0856
Epoch 4/10 - Loss: 4.7187 - Acc: 0.3194
Epoch 5/10 - Loss: 3.6411 - Acc: 0.5786
Epoch 6/10 - Loss: 3.2571 - Acc: 0.6922
Epoch 7/10 - Loss: 3.0493 - Acc: 0.7776
Epoch 8/10 - Loss: 3.0162 - Acc: 0.8078
Epoch 9/10 - Loss: 3.1431 - Acc: 0.8036
Epoch 10/10 - Loss: 2.8847 - Acc: 0.8608
Saved: results_resnet_cifar100/lambda_sweep/lambda_200/model_task9.pt
Computing Fisher for Task 9...
Computing Fisher Matrix...
Fisher Matrix computed.

============================================================
Training Complete!
============================================================
[2/7] Evaluating λ=200...
/Users/sunilkumars/Desktop/EWC Project/drift_cl_edge/venv/lib/python3.13/site-packages/torchvision/datasets/cifar.py:83: VisibleDeprecationWarning: dtype(): align should be passed as Python or NumPy boolean but got `align=0`. Did you mean to pass a tuple to create a subarray type? (Deprecated NumPy 2.4)
  entry = pickle.load(f, encoding="latin1")
Using device: mps
Split-CIFAR-100 initialized:
  Tasks: 10
  Classes per task: 10
  Class order: [83 53 70 45 44 39 22 80 10  0 18 30 73 33 90  4 76 77 12 31]... (first 20)
Task 0: Classes [83, 53, 70, 45, 44, 39, 22, 80, 10, 0]
  Train samples: 5000
  Test samples: 1000
Task 1: Classes [18, 30, 73, 33, 90, 4, 76, 77, 12, 31]
  Train samples: 5000
  Test samples: 1000
Task 2: Classes [55, 88, 26, 42, 69, 15, 40, 96, 9, 72]
  Train samples: 5000
  Test samples: 1000
Task 3: Classes [11, 47, 85, 28, 93, 5, 66, 65, 35, 16]
  Train samples: 5000
  Test samples: 1000
Task 4: Classes [49, 34, 7, 95, 27, 19, 81, 25, 62, 13]
  Train samples: 5000
  Test samples: 1000
Task 5: Classes [24, 3, 17, 38, 8, 78, 6, 64, 36, 89]
  Train samples: 5000
  Test samples: 1000
Task 6: Classes [56, 99, 54, 43, 50, 67, 46, 68, 61, 97]
  Train samples: 5000
  Test samples: 1000
Task 7: Classes [79, 41, 58, 48, 98, 57, 75, 32, 94, 59]
  Train samples: 5000
  Test samples: 1000
Task 8: Classes [63, 84, 37, 29, 1, 52, 21, 2, 23, 87]
  Train samples: 5000
  Test samples: 1000
Task 9: Classes [91, 74, 86, 82, 20, 60, 71, 14, 92, 51]
  Train samples: 5000
  Test samples: 1000
Task 0: Classes [83, 53, 70, 45, 44, 39, 22, 80, 10, 0]
  Train samples: 5000
  Test samples: 1000
Evaluating on Task 0 (Classes: [83, 53, 70, 45, 44, 39, 22, 80, 10, 0])...
Task 0 Accuracy: 0.0000
Task 1: Classes [18, 30, 73, 33, 90, 4, 76, 77, 12, 31]
  Train samples: 5000
  Test samples: 1000
Evaluating on Task 1 (Classes: [18, 30, 73, 33, 90, 4, 76, 77, 12, 31])...
Task 1 Accuracy: 0.0000
Task 2: Classes [55, 88, 26, 42, 69, 15, 40, 96, 9, 72]
  Train samples: 5000
  Test samples: 1000
Evaluating on Task 2 (Classes: [55, 88, 26, 42, 69, 15, 40, 96, 9, 72])...
Task 2 Accuracy: 0.0000
Task 3: Classes [11, 47, 85, 28, 93, 5, 66, 65, 35, 16]
  Train samples: 5000
  Test samples: 1000
Evaluating on Task 3 (Classes: [11, 47, 85, 28, 93, 5, 66, 65, 35, 16])...
Task 3 Accuracy: 0.0000
Task 4: Classes [49, 34, 7, 95, 27, 19, 81, 25, 62, 13]
  Train samples: 5000
  Test samples: 1000
Evaluating on Task 4 (Classes: [49, 34, 7, 95, 27, 19, 81, 25, 62, 13])...
Task 4 Accuracy: 0.0000
Task 5: Classes [24, 3, 17, 38, 8, 78, 6, 64, 36, 89]
  Train samples: 5000
  Test samples: 1000
Evaluating on Task 5 (Classes: [24, 3, 17, 38, 8, 78, 6, 64, 36, 89])...
Task 5 Accuracy: 0.0010
Task 6: Classes [56, 99, 54, 43, 50, 67, 46, 68, 61, 97]
  Train samples: 5000
  Test samples: 1000
Evaluating on Task 6 (Classes: [56, 99, 54, 43, 50, 67, 46, 68, 61, 97])...
Task 6 Accuracy: 0.0000
Task 7: Classes [79, 41, 58, 48, 98, 57, 75, 32, 94, 59]
  Train samples: 5000
  Test samples: 1000
Evaluating on Task 7 (Classes: [79, 41, 58, 48, 98, 57, 75, 32, 94, 59])...
Task 7 Accuracy: 0.0000
Task 8: Classes [63, 84, 37, 29, 1, 52, 21, 2, 23, 87]
  Train samples: 5000
  Test samples: 1000
Evaluating on Task 8 (Classes: [63, 84, 37, 29, 1, 52, 21, 2, 23, 87])...
Task 8 Accuracy: 0.0000
Task 9: Classes [91, 74, 86, 82, 20, 60, 71, 14, 92, 51]
  Train samples: 5000
  Test samples: 1000
Evaluating on Task 9 (Classes: [91, 74, 86, 82, 20, 60, 71, 14, 92, 51])...
Task 9 Accuracy: 0.5820

============================================================
Final Accuracies: ['0.0000', '0.0000', '0.0000', '0.0000', '0.0000', '0.0010', '0.0000', '0.0000', '0.0000', '0.5820']
Average Accuracy: 0.0583
Final Task: 0.5820
Early Tasks Avg: 0.0001
============================================================
Results saved to results_resnet_cifar100/lambda_sweep/lambda_200_results.json

[3/7] Training λ=500...
/Users/sunilkumars/Desktop/EWC Project/drift_cl_edge/venv/lib/python3.13/site-packages/torchvision/datasets/cifar.py:83: VisibleDeprecationWarning: dtype(): align should be passed as Python or NumPy boolean but got `align=0`. Did you mean to pass a tuple to create a subarray type? (Deprecated NumPy 2.4)
  entry = pickle.load(f, encoding="latin1")
/Users/sunilkumars/Desktop/EWC Project/drift_cl_edge/venv/lib/python3.13/site-packages/torch/utils/data/dataloader.py:692: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, device pinned memory won't be used.
  warnings.warn(warn_msg)
Using device: mps
Training ResNet-18 on Split-CIFAR-100: 10 tasks, 10 epochs/task, λ=500.0
Split-CIFAR-100 initialized:
  Tasks: 10
  Classes per task: 10
  Class order: [83 53 70 45 44 39 22 80 10  0 18 30 73 33 90  4 76 77 12 31]... (first 20)
Task 0: Classes [83, 53, 70, 45, 44, 39, 22, 80, 10, 0]
  Train samples: 5000
  Test samples: 1000
Task 1: Classes [18, 30, 73, 33, 90, 4, 76, 77, 12, 31]
  Train samples: 5000
  Test samples: 1000
Task 2: Classes [55, 88, 26, 42, 69, 15, 40, 96, 9, 72]
  Train samples: 5000
  Test samples: 1000
Task 3: Classes [11, 47, 85, 28, 93, 5, 66, 65, 35, 16]
  Train samples: 5000
  Test samples: 1000
Task 4: Classes [49, 34, 7, 95, 27, 19, 81, 25, 62, 13]
  Train samples: 5000
  Test samples: 1000
Task 5: Classes [24, 3, 17, 38, 8, 78, 6, 64, 36, 89]
  Train samples: 5000
  Test samples: 1000
Task 6: Classes [56, 99, 54, 43, 50, 67, 46, 68, 61, 97]
  Train samples: 5000
  Test samples: 1000
Task 7: Classes [79, 41, 58, 48, 98, 57, 75, 32, 94, 59]
  Train samples: 5000
  Test samples: 1000
Task 8: Classes [63, 84, 37, 29, 1, 52, 21, 2, 23, 87]
  Train samples: 5000
  Test samples: 1000
Task 9: Classes [91, 74, 86, 82, 20, 60, 71, 14, 92, 51]
  Train samples: 5000
  Test samples: 1000

============================================================
Training on Task 0 (Classes: [83, 53, 70, 45, 44, 39, 22, 80, 10, 0])
============================================================
Epoch 1/10 - Loss: 1.9295 - Acc: 0.3424
Epoch 2/10 - Loss: 1.5132 - Acc: 0.4514
Epoch 3/10 - Loss: 1.3398 - Acc: 0.5152
Epoch 4/10 - Loss: 1.2280 - Acc: 0.5646
Epoch 5/10 - Loss: 1.1511 - Acc: 0.5956
Epoch 6/10 - Loss: 0.9733 - Acc: 0.6488
Epoch 7/10 - Loss: 0.8913 - Acc: 0.6944
Epoch 8/10 - Loss: 0.7731 - Acc: 0.7292
Epoch 9/10 - Loss: 0.6452 - Acc: 0.7828
Epoch 10/10 - Loss: 0.5401 - Acc: 0.8120
Saved: results_resnet_cifar100/lambda_sweep/lambda_500/model_task0.pt
Computing Fisher for Task 0...
Computing Fisher Matrix...
Fisher Matrix computed.

============================================================
Training on Task 1 (Classes: [18, 30, 73, 33, 90, 4, 76, 77, 12, 31])
============================================================
Epoch 1/10 - Loss: 3.3957 - Acc: 0.2782
Epoch 2/10 - Loss: 1.7168 - Acc: 0.4784
Epoch 3/10 - Loss: 1.3653 - Acc: 0.5956
Epoch 4/10 - Loss: 1.2597 - Acc: 0.6306
Epoch 5/10 - Loss: 1.0090 - Acc: 0.7362
Epoch 6/10 - Loss: 1.0649 - Acc: 0.7312
Epoch 7/10 - Loss: 0.9797 - Acc: 0.7644
Epoch 8/10 - Loss: 0.7143 - Acc: 0.8570
Epoch 9/10 - Loss: 0.7918 - Acc: 0.8514
Epoch 10/10 - Loss: 1.2004 - Acc: 0.7866
Saved: results_resnet_cifar100/lambda_sweep/lambda_500/model_task1.pt
Computing Fisher for Task 1...
Computing Fisher Matrix...
Fisher Matrix computed.

============================================================
Training on Task 2 (Classes: [55, 88, 26, 42, 69, 15, 40, 96, 9, 72])
============================================================
Epoch 1/10 - Loss: 7.0651 - Acc: 0.1130
Epoch 2/10 - Loss: 2.6685 - Acc: 0.3838
Epoch 3/10 - Loss: 2.1096 - Acc: 0.5222
Epoch 4/10 - Loss: 1.8463 - Acc: 0.5982
Epoch 5/10 - Loss: 1.7745 - Acc: 0.6690
Epoch 6/10 - Loss: 1.8585 - Acc: 0.6910
Epoch 7/10 - Loss: 1.9200 - Acc: 0.6988
Epoch 8/10 - Loss: 1.9167 - Acc: 0.7308
Epoch 9/10 - Loss: 1.7033 - Acc: 0.7872
Epoch 10/10 - Loss: 1.8183 - Acc: 0.8126
Saved: results_resnet_cifar100/lambda_sweep/lambda_500/model_task2.pt
Computing Fisher for Task 2...
Computing Fisher Matrix...
Fisher Matrix computed.

============================================================
Training on Task 3 (Classes: [11, 47, 85, 28, 93, 5, 66, 65, 35, 16])
============================================================
Epoch 1/10 - Loss: 11.4122 - Acc: 0.0606
Epoch 2/10 - Loss: 3.2270 - Acc: 0.3942
Epoch 3/10 - Loss: 2.5388 - Acc: 0.5938
Epoch 4/10 - Loss: 2.3824 - Acc: 0.6626
Epoch 5/10 - Loss: 2.3648 - Acc: 0.6976
Epoch 6/10 - Loss: 2.2489 - Acc: 0.7432
Epoch 7/10 - Loss: 2.5441 - Acc: 0.7364
Epoch 8/10 - Loss: 2.0410 - Acc: 0.8226
Epoch 9/10 - Loss: 2.5625 - Acc: 0.7790
Epoch 10/10 - Loss: 1.9505 - Acc: 0.8726
Saved: results_resnet_cifar100/lambda_sweep/lambda_500/model_task3.pt
Computing Fisher for Task 3...
Computing Fisher Matrix...
Fisher Matrix computed.

============================================================
Training on Task 4 (Classes: [49, 34, 7, 95, 27, 19, 81, 25, 62, 13])
============================================================
Epoch 1/10 - Loss: 14.7434 - Acc: 0.0612
Epoch 2/10 - Loss: 3.5475 - Acc: 0.4540
Epoch 3/10 - Loss: 2.6977 - Acc: 0.6584
Epoch 4/10 - Loss: 2.4061 - Acc: 0.7486
Epoch 5/10 - Loss: 2.5024 - Acc: 0.7492
Epoch 6/10 - Loss: 2.3107 - Acc: 0.8058
Epoch 7/10 - Loss: 2.7094 - Acc: 0.7712
Epoch 8/10 - Loss: 2.2606 - Acc: 0.8266
Epoch 9/10 - Loss: 2.2810 - Acc: 0.8416
Epoch 10/10 - Loss: 2.2291 - Acc: 0.8606
Saved: results_resnet_cifar100/lambda_sweep/lambda_500/model_task4.pt
Computing Fisher for Task 4...
Computing Fisher Matrix...
Fisher Matrix computed.

============================================================
Training on Task 5 (Classes: [24, 3, 17, 38, 8, 78, 6, 64, 36, 89])
============================================================
Epoch 1/10 - Loss: 16.7562 - Acc: 0.0344
Epoch 2/10 - Loss: 5.7833 - Acc: 0.2678
Epoch 3/10 - Loss: 3.1379 - Acc: 0.5782
Epoch 4/10 - Loss: 2.9778 - Acc: 0.6582
Epoch 5/10 - Loss: 2.9262 - Acc: 0.7084
Epoch 6/10 - Loss: 2.6562 - Acc: 0.7464
Epoch 7/10 - Loss: 2.9677 - Acc: 0.7456
Epoch 8/10 - Loss: 2.9151 - Acc: 0.7724
Epoch 9/10 - Loss: 2.6978 - Acc: 0.8110
Epoch 10/10 - Loss: 2.9254 - Acc: 0.8028
Saved: results_resnet_cifar100/lambda_sweep/lambda_500/model_task5.pt
Computing Fisher for Task 5...
Computing Fisher Matrix...
Fisher Matrix computed.

============================================================
Training on Task 6 (Classes: [56, 99, 54, 43, 50, 67, 46, 68, 61, 97])
============================================================
Epoch 1/10 - Loss: 19.8072 - Acc: 0.0108
Epoch 2/10 - Loss: 7.4596 - Acc: 0.1808
Epoch 3/10 - Loss: 3.5990 - Acc: 0.5286
Epoch 4/10 - Loss: 3.0166 - Acc: 0.7178
Epoch 5/10 - Loss: 2.8866 - Acc: 0.7618
Epoch 6/10 - Loss: 2.8577 - Acc: 0.7672
Epoch 7/10 - Loss: 2.7372 - Acc: 0.7944
Epoch 8/10 - Loss: 3.0416 - Acc: 0.7944
Epoch 9/10 - Loss: 2.8321 - Acc: 0.8242
Epoch 10/10 - Loss: 2.8098 - Acc: 0.8302
Saved: results_resnet_cifar100/lambda_sweep/lambda_500/model_task6.pt
Computing Fisher for Task 6...
Computing Fisher Matrix...
Fisher Matrix computed.

============================================================
Training on Task 7 (Classes: [79, 41, 58, 48, 98, 57, 75, 32, 94, 59])
============================================================
Epoch 1/10 - Loss: 25.1454 - Acc: 0.0000
Epoch 2/10 - Loss: 9.5410 - Acc: 0.0586
Epoch 3/10 - Loss: 4.9968 - Acc: 0.3740
Epoch 4/10 - Loss: 3.4441 - Acc: 0.6702
Epoch 5/10 - Loss: 3.0025 - Acc: 0.7614
Epoch 6/10 - Loss: 3.0398 - Acc: 0.7972
Epoch 7/10 - Loss: 2.8879 - Acc: 0.8238
Epoch 8/10 - Loss: 2.8254 - Acc: 0.8320
Epoch 9/10 - Loss: 2.4753 - Acc: 0.8874
Epoch 10/10 - Loss: 2.7367 - Acc: 0.8600
Saved: results_resnet_cifar100/lambda_sweep/lambda_500/model_task7.pt
Computing Fisher for Task 7...
Computing Fisher Matrix...
Fisher Matrix computed.

============================================================
Training on Task 8 (Classes: [63, 84, 37, 29, 1, 52, 21, 2, 23, 87])
============================================================
Epoch 1/10 - Loss: 24.9526 - Acc: 0.0016
Epoch 2/10 - Loss: 10.3694 - Acc: 0.0450
Epoch 3/10 - Loss: 6.1374 - Acc: 0.2934
Epoch 4/10 - Loss: 3.5374 - Acc: 0.6790
Epoch 5/10 - Loss: 3.3621 - Acc: 0.7370
Epoch 6/10 - Loss: 2.9004 - Acc: 0.8118
Epoch 7/10 - Loss: 3.1518 - Acc: 0.8036
Epoch 8/10 - Loss: 3.0933 - Acc: 0.8040
Epoch 9/10 - Loss: 2.8820 - Acc: 0.8410
Epoch 10/10 - Loss: 2.8811 - Acc: 0.8496
Saved: results_resnet_cifar100/lambda_sweep/lambda_500/model_task8.pt
Computing Fisher for Task 8...
Computing Fisher Matrix...
Fisher Matrix computed.

============================================================
Training on Task 9 (Classes: [91, 74, 86, 82, 20, 60, 71, 14, 92, 51])
============================================================
Epoch 1/10 - Loss: 28.7005 - Acc: 0.0000
Epoch 2/10 - Loss: 15.6756 - Acc: 0.0000
Epoch 3/10 - Loss: 9.9870 - Acc: 0.0602
Epoch 4/10 - Loss: 7.4114 - Acc: 0.2642
Epoch 5/10 - Loss: 4.7071 - Acc: 0.5368
Epoch 6/10 - Loss: 3.7662 - Acc: 0.6886
Epoch 7/10 - Loss: 3.3858 - Acc: 0.7522
Epoch 8/10 - Loss: 3.3600 - Acc: 0.7680
Epoch 9/10 - Loss: 3.1764 - Acc: 0.7792
Epoch 10/10 - Loss: 2.8262 - Acc: 0.8232
Saved: results_resnet_cifar100/lambda_sweep/lambda_500/model_task9.pt
Computing Fisher for Task 9...
Computing Fisher Matrix...
Fisher Matrix computed.

============================================================
Training Complete!
============================================================
[3/7] Evaluating λ=500...
/Users/sunilkumars/Desktop/EWC Project/drift_cl_edge/venv/lib/python3.13/site-packages/torchvision/datasets/cifar.py:83: VisibleDeprecationWarning: dtype(): align should be passed as Python or NumPy boolean but got `align=0`. Did you mean to pass a tuple to create a subarray type? (Deprecated NumPy 2.4)
  entry = pickle.load(f, encoding="latin1")
Using device: mps
Split-CIFAR-100 initialized:
  Tasks: 10
  Classes per task: 10
  Class order: [83 53 70 45 44 39 22 80 10  0 18 30 73 33 90  4 76 77 12 31]... (first 20)
Task 0: Classes [83, 53, 70, 45, 44, 39, 22, 80, 10, 0]
  Train samples: 5000
  Test samples: 1000
Task 1: Classes [18, 30, 73, 33, 90, 4, 76, 77, 12, 31]
  Train samples: 5000
  Test samples: 1000
Task 2: Classes [55, 88, 26, 42, 69, 15, 40, 96, 9, 72]
  Train samples: 5000
  Test samples: 1000
Task 3: Classes [11, 47, 85, 28, 93, 5, 66, 65, 35, 16]
  Train samples: 5000
  Test samples: 1000
Task 4: Classes [49, 34, 7, 95, 27, 19, 81, 25, 62, 13]
  Train samples: 5000
  Test samples: 1000
Task 5: Classes [24, 3, 17, 38, 8, 78, 6, 64, 36, 89]
  Train samples: 5000
  Test samples: 1000
Task 6: Classes [56, 99, 54, 43, 50, 67, 46, 68, 61, 97]
  Train samples: 5000
  Test samples: 1000
Task 7: Classes [79, 41, 58, 48, 98, 57, 75, 32, 94, 59]
  Train samples: 5000
  Test samples: 1000
Task 8: Classes [63, 84, 37, 29, 1, 52, 21, 2, 23, 87]
  Train samples: 5000
  Test samples: 1000
Task 9: Classes [91, 74, 86, 82, 20, 60, 71, 14, 92, 51]
  Train samples: 5000
  Test samples: 1000
Task 0: Classes [83, 53, 70, 45, 44, 39, 22, 80, 10, 0]
  Train samples: 5000
  Test samples: 1000
Evaluating on Task 0 (Classes: [83, 53, 70, 45, 44, 39, 22, 80, 10, 0])...
Task 0 Accuracy: 0.0000
Task 1: Classes [18, 30, 73, 33, 90, 4, 76, 77, 12, 31]
  Train samples: 5000
  Test samples: 1000
Evaluating on Task 1 (Classes: [18, 30, 73, 33, 90, 4, 76, 77, 12, 31])...
Task 1 Accuracy: 0.0000
Task 2: Classes [55, 88, 26, 42, 69, 15, 40, 96, 9, 72]
  Train samples: 5000
  Test samples: 1000
Evaluating on Task 2 (Classes: [55, 88, 26, 42, 69, 15, 40, 96, 9, 72])...
Task 2 Accuracy: 0.0000
Task 3: Classes [11, 47, 85, 28, 93, 5, 66, 65, 35, 16]
  Train samples: 5000
  Test samples: 1000
Evaluating on Task 3 (Classes: [11, 47, 85, 28, 93, 5, 66, 65, 35, 16])...
Task 3 Accuracy: 0.0000
Task 4: Classes [49, 34, 7, 95, 27, 19, 81, 25, 62, 13]
  Train samples: 5000
  Test samples: 1000
Evaluating on Task 4 (Classes: [49, 34, 7, 95, 27, 19, 81, 25, 62, 13])...
Task 4 Accuracy: 0.0000
Task 5: Classes [24, 3, 17, 38, 8, 78, 6, 64, 36, 89]
  Train samples: 5000
  Test samples: 1000
Evaluating on Task 5 (Classes: [24, 3, 17, 38, 8, 78, 6, 64, 36, 89])...
Task 5 Accuracy: 0.0000
Task 6: Classes [56, 99, 54, 43, 50, 67, 46, 68, 61, 97]
  Train samples: 5000
  Test samples: 1000
Evaluating on Task 6 (Classes: [56, 99, 54, 43, 50, 67, 46, 68, 61, 97])...
Task 6 Accuracy: 0.0000
Task 7: Classes [79, 41, 58, 48, 98, 57, 75, 32, 94, 59]
  Train samples: 5000
  Test samples: 1000
Evaluating on Task 7 (Classes: [79, 41, 58, 48, 98, 57, 75, 32, 94, 59])...
Task 7 Accuracy: 0.0000
Task 8: Classes [63, 84, 37, 29, 1, 52, 21, 2, 23, 87]
  Train samples: 5000
  Test samples: 1000
Evaluating on Task 8 (Classes: [63, 84, 37, 29, 1, 52, 21, 2, 23, 87])...
Task 8 Accuracy: 0.0000
Task 9: Classes [91, 74, 86, 82, 20, 60, 71, 14, 92, 51]
  Train samples: 5000
  Test samples: 1000
Evaluating on Task 9 (Classes: [91, 74, 86, 82, 20, 60, 71, 14, 92, 51])...
Task 9 Accuracy: 0.6880

============================================================
Final Accuracies: ['0.0000', '0.0000', '0.0000', '0.0000', '0.0000', '0.0000', '0.0000', '0.0000', '0.0000', '0.6880']
Average Accuracy: 0.0688
Final Task: 0.6880
Early Tasks Avg: 0.0000
============================================================
Results saved to results_resnet_cifar100/lambda_sweep/lambda_500_results.json

[4/7] Training λ=1000...
/Users/sunilkumars/Desktop/EWC Project/drift_cl_edge/venv/lib/python3.13/site-packages/torchvision/datasets/cifar.py:83: VisibleDeprecationWarning: dtype(): align should be passed as Python or NumPy boolean but got `align=0`. Did you mean to pass a tuple to create a subarray type? (Deprecated NumPy 2.4)
  entry = pickle.load(f, encoding="latin1")
/Users/sunilkumars/Desktop/EWC Project/drift_cl_edge/venv/lib/python3.13/site-packages/torch/utils/data/dataloader.py:692: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, device pinned memory won't be used.
  warnings.warn(warn_msg)
Using device: mps
Training ResNet-18 on Split-CIFAR-100: 10 tasks, 10 epochs/task, λ=1000.0
Split-CIFAR-100 initialized:
  Tasks: 10
  Classes per task: 10
  Class order: [83 53 70 45 44 39 22 80 10  0 18 30 73 33 90  4 76 77 12 31]... (first 20)
Task 0: Classes [83, 53, 70, 45, 44, 39, 22, 80, 10, 0]
  Train samples: 5000
  Test samples: 1000
Task 1: Classes [18, 30, 73, 33, 90, 4, 76, 77, 12, 31]
  Train samples: 5000
  Test samples: 1000
Task 2: Classes [55, 88, 26, 42, 69, 15, 40, 96, 9, 72]
  Train samples: 5000
  Test samples: 1000
Task 3: Classes [11, 47, 85, 28, 93, 5, 66, 65, 35, 16]
  Train samples: 5000
  Test samples: 1000
Task 4: Classes [49, 34, 7, 95, 27, 19, 81, 25, 62, 13]
  Train samples: 5000
  Test samples: 1000
Task 5: Classes [24, 3, 17, 38, 8, 78, 6, 64, 36, 89]
  Train samples: 5000
  Test samples: 1000
Task 6: Classes [56, 99, 54, 43, 50, 67, 46, 68, 61, 97]
  Train samples: 5000
  Test samples: 1000
Task 7: Classes [79, 41, 58, 48, 98, 57, 75, 32, 94, 59]
  Train samples: 5000
  Test samples: 1000
Task 8: Classes [63, 84, 37, 29, 1, 52, 21, 2, 23, 87]
  Train samples: 5000
  Test samples: 1000
Task 9: Classes [91, 74, 86, 82, 20, 60, 71, 14, 92, 51]
  Train samples: 5000
  Test samples: 1000

============================================================
Training on Task 0 (Classes: [83, 53, 70, 45, 44, 39, 22, 80, 10, 0])
============================================================
Epoch 1/10 - Loss: 1.8532 - Acc: 0.3762
Epoch 2/10 - Loss: 1.3788 - Acc: 0.5052
Epoch 3/10 - Loss: 1.1941 - Acc: 0.5730
Epoch 4/10 - Loss: 1.0793 - Acc: 0.6188
Epoch 5/10 - Loss: 1.0033 - Acc: 0.6480
Epoch 6/10 - Loss: 0.8454 - Acc: 0.7102
Epoch 7/10 - Loss: 0.7233 - Acc: 0.7428
Epoch 8/10 - Loss: 0.5107 - Acc: 0.8286
Epoch 9/10 - Loss: 0.5462 - Acc: 0.8074
Epoch 10/10 - Loss: 0.3301 - Acc: 0.8870
Saved: results_resnet_cifar100/lambda_sweep/lambda_1000/model_task0.pt
Computing Fisher for Task 0...
Computing Fisher Matrix...
Fisher Matrix computed.

============================================================
Training on Task 1 (Classes: [18, 30, 73, 33, 90, 4, 76, 77, 12, 31])
============================================================
Epoch 1/10 - Loss: 3.3274 - Acc: 0.3168
Epoch 2/10 - Loss: 1.4307 - Acc: 0.5770
Epoch 3/10 - Loss: 1.1092 - Acc: 0.6864
Epoch 4/10 - Loss: 0.8877 - Acc: 0.7756
Epoch 5/10 - Loss: 0.8924 - Acc: 0.7858
Epoch 6/10 - Loss: 0.6280 - Acc: 0.8982
Epoch 7/10 - Loss: 0.8008 - Acc: 0.8516
Epoch 8/10 - Loss: 0.6012 - Acc: 0.9310
Epoch 9/10 - Loss: 0.8413 - Acc: 0.8698
Epoch 10/10 - Loss: 0.9797 - Acc: 0.8608
Saved: results_resnet_cifar100/lambda_sweep/lambda_1000/model_task1.pt
Computing Fisher for Task 1...
Computing Fisher Matrix...
Fisher Matrix computed.

============================================================
Training on Task 2 (Classes: [55, 88, 26, 42, 69, 15, 40, 96, 9, 72])
============================================================
Epoch 1/10 - Loss: 6.1410 - Acc: 0.2178
Epoch 2/10 - Loss: 2.3104 - Acc: 0.4680
Epoch 3/10 - Loss: 1.8199 - Acc: 0.6018
Epoch 4/10 - Loss: 1.7039 - Acc: 0.6608
Epoch 5/10 - Loss: 1.4848 - Acc: 0.7542
Epoch 6/10 - Loss: 1.4907 - Acc: 0.7910
Epoch 7/10 - Loss: 1.7115 - Acc: 0.7724
Epoch 8/10 - Loss: 1.7680 - Acc: 0.7990
Epoch 9/10 - Loss: 1.5077 - Acc: 0.8606
Epoch 10/10 - Loss: 1.7750 - Acc: 0.8348
Saved: results_resnet_cifar100/lambda_sweep/lambda_1000/model_task2.pt
Computing Fisher for Task 2...
Computing Fisher Matrix...
Fisher Matrix computed.

============================================================
Training on Task 3 (Classes: [11, 47, 85, 28, 93, 5, 66, 65, 35, 16])
============================================================
Epoch 1/10 - Loss: 10.5376 - Acc: 0.0914
Epoch 2/10 - Loss: 3.3136 - Acc: 0.4226
Epoch 3/10 - Loss: 2.6318 - Acc: 0.6024
Epoch 4/10 - Loss: 2.4201 - Acc: 0.7014
Epoch 5/10 - Loss: 2.4329 - Acc: 0.7430
Epoch 6/10 - Loss: 2.3184 - Acc: 0.7940
Epoch 7/10 - Loss: 2.2986 - Acc: 0.8266
Epoch 8/10 - Loss: 1.9975 - Acc: 0.8938
Epoch 9/10 - Loss: 2.8170 - Acc: 0.8154
Epoch 10/10 - Loss: 2.4247 - Acc: 0.8846
Saved: results_resnet_cifar100/lambda_sweep/lambda_1000/model_task3.pt
Computing Fisher for Task 3...
Computing Fisher Matrix...
Fisher Matrix computed.

============================================================
Training on Task 4 (Classes: [49, 34, 7, 95, 27, 19, 81, 25, 62, 13])
============================================================
Epoch 1/10 - Loss: 14.1184 - Acc: 0.0716
Epoch 2/10 - Loss: 3.8942 - Acc: 0.4070
Epoch 3/10 - Loss: 2.8583 - Acc: 0.6494
Epoch 4/10 - Loss: 2.6793 - Acc: 0.7442
Epoch 5/10 - Loss: 2.7640 - Acc: 0.7556
Epoch 6/10 - Loss: 2.5575 - Acc: 0.8210
Epoch 7/10 - Loss: 2.7073 - Acc: 0.8222
Epoch 8/10 - Loss: 2.6773 - Acc: 0.8354
Epoch 9/10 - Loss: 2.3823 - Acc: 0.8912
Epoch 10/10 - Loss: 2.4443 - Acc: 0.8926
Saved: results_resnet_cifar100/lambda_sweep/lambda_1000/model_task4.pt
Computing Fisher for Task 4...
Computing Fisher Matrix...
Fisher Matrix computed.

============================================================
Training on Task 5 (Classes: [24, 3, 17, 38, 8, 78, 6, 64, 36, 89])
============================================================
Epoch 1/10 - Loss: 18.4909 - Acc: 0.0428
Epoch 2/10 - Loss: 4.2815 - Acc: 0.4730
Epoch 3/10 - Loss: 3.8796 - Acc: 0.6478
Epoch 4/10 - Loss: 3.6194 - Acc: 0.7052
Epoch 5/10 - Loss: 3.8565 - Acc: 0.7040
Epoch 6/10 - Loss: 3.4806 - Acc: 0.7574
Epoch 7/10 - Loss: 3.6229 - Acc: 0.7714
Epoch 8/10 - Loss: 3.7031 - Acc: 0.7896
Epoch 9/10 - Loss: 3.4540 - Acc: 0.8360
Epoch 10/10 - Loss: 3.9096 - Acc: 0.8136
Saved: results_resnet_cifar100/lambda_sweep/lambda_1000/model_task5.pt
Computing Fisher for Task 5...
Computing Fisher Matrix...
Fisher Matrix computed.

============================================================
Training on Task 6 (Classes: [56, 99, 54, 43, 50, 67, 46, 68, 61, 97])
============================================================
Epoch 1/10 - Loss: 22.4188 - Acc: 0.0236
Epoch 2/10 - Loss: 6.3049 - Acc: 0.2606
Epoch 3/10 - Loss: 3.9257 - Acc: 0.6508
Epoch 4/10 - Loss: 3.7927 - Acc: 0.7200
Epoch 5/10 - Loss: 3.8314 - Acc: 0.7440
Epoch 6/10 - Loss: 3.8003 - Acc: 0.7608
Epoch 7/10 - Loss: 3.6593 - Acc: 0.7902
Epoch 8/10 - Loss: 3.9783 - Acc: 0.7802
Epoch 9/10 - Loss: 3.7823 - Acc: 0.8022
Epoch 10/10 - Loss: 4.0364 - Acc: 0.8012
Saved: results_resnet_cifar100/lambda_sweep/lambda_1000/model_task6.pt
Computing Fisher for Task 6...
Computing Fisher Matrix...
Fisher Matrix computed.

============================================================
Training on Task 7 (Classes: [79, 41, 58, 48, 98, 57, 75, 32, 94, 59])
============================================================
Epoch 1/10 - Loss: 26.1300 - Acc: 0.0006
Epoch 2/10 - Loss: 9.4180 - Acc: 0.1330
Epoch 3/10 - Loss: 4.7154 - Acc: 0.5650
Epoch 4/10 - Loss: 4.0261 - Acc: 0.7582
Epoch 5/10 - Loss: 3.7549 - Acc: 0.7930
Epoch 6/10 - Loss: 3.9270 - Acc: 0.7810
Epoch 7/10 - Loss: 3.9638 - Acc: 0.8012
Epoch 8/10 - Loss: 3.8803 - Acc: 0.8158
Epoch 9/10 - Loss: 3.8483 - Acc: 0.8282
Epoch 10/10 - Loss: 4.4096 - Acc: 0.8006
Saved: results_resnet_cifar100/lambda_sweep/lambda_1000/model_task7.pt
Computing Fisher for Task 7...
Computing Fisher Matrix...
Fisher Matrix computed.

============================================================
Training on Task 8 (Classes: [63, 84, 37, 29, 1, 52, 21, 2, 23, 87])
============================================================
Epoch 1/10 - Loss: 27.9565 - Acc: 0.0000
Epoch 2/10 - Loss: 11.2678 - Acc: 0.0416
Epoch 3/10 - Loss: 6.9551 - Acc: 0.3454
Epoch 4/10 - Loss: 4.2675 - Acc: 0.7082
Epoch 5/10 - Loss: 4.0389 - Acc: 0.7548
Epoch 6/10 - Loss: 3.8989 - Acc: 0.7750
Epoch 7/10 - Loss: 3.8002 - Acc: 0.7964
Epoch 8/10 - Loss: 4.0313 - Acc: 0.7864
Epoch 9/10 - Loss: 3.9916 - Acc: 0.8018
Epoch 10/10 - Loss: 3.7719 - Acc: 0.8086
Saved: results_resnet_cifar100/lambda_sweep/lambda_1000/model_task8.pt
Computing Fisher for Task 8...
Computing Fisher Matrix...
Fisher Matrix computed.

============================================================
Training on Task 9 (Classes: [91, 74, 86, 82, 20, 60, 71, 14, 92, 51])
============================================================
Epoch 1/10 - Loss: 32.6581 - Acc: 0.0000
Epoch 2/10 - Loss: 13.6336 - Acc: 0.0192
Epoch 3/10 - Loss: 10.3604 - Acc: 0.1808
Epoch 4/10 - Loss: 5.3512 - Acc: 0.5200
Epoch 5/10 - Loss: 4.3805 - Acc: 0.7032
Epoch 6/10 - Loss: 4.6747 - Acc: 0.7208
Epoch 7/10 - Loss: 4.0025 - Acc: 0.7594
Epoch 8/10 - Loss: 3.9782 - Acc: 0.7692
Epoch 9/10 - Loss: 3.8704 - Acc: 0.7796
Epoch 10/10 - Loss: 4.0047 - Acc: 0.7732
Saved: results_resnet_cifar100/lambda_sweep/lambda_1000/model_task9.pt
Computing Fisher for Task 9...
Computing Fisher Matrix...
Fisher Matrix computed.

============================================================
Training Complete!
============================================================
[4/7] Evaluating λ=1000...
/Users/sunilkumars/Desktop/EWC Project/drift_cl_edge/venv/lib/python3.13/site-packages/torchvision/datasets/cifar.py:83: VisibleDeprecationWarning: dtype(): align should be passed as Python or NumPy boolean but got `align=0`. Did you mean to pass a tuple to create a subarray type? (Deprecated NumPy 2.4)
  entry = pickle.load(f, encoding="latin1")
Using device: mps
Split-CIFAR-100 initialized:
  Tasks: 10
  Classes per task: 10
  Class order: [83 53 70 45 44 39 22 80 10  0 18 30 73 33 90  4 76 77 12 31]... (first 20)
Task 0: Classes [83, 53, 70, 45, 44, 39, 22, 80, 10, 0]
  Train samples: 5000
  Test samples: 1000
Task 1: Classes [18, 30, 73, 33, 90, 4, 76, 77, 12, 31]
  Train samples: 5000
  Test samples: 1000
Task 2: Classes [55, 88, 26, 42, 69, 15, 40, 96, 9, 72]
  Train samples: 5000
  Test samples: 1000
Task 3: Classes [11, 47, 85, 28, 93, 5, 66, 65, 35, 16]
  Train samples: 5000
  Test samples: 1000
Task 4: Classes [49, 34, 7, 95, 27, 19, 81, 25, 62, 13]
  Train samples: 5000
  Test samples: 1000
Task 5: Classes [24, 3, 17, 38, 8, 78, 6, 64, 36, 89]
  Train samples: 5000
  Test samples: 1000
Task 6: Classes [56, 99, 54, 43, 50, 67, 46, 68, 61, 97]
  Train samples: 5000
  Test samples: 1000
Task 7: Classes [79, 41, 58, 48, 98, 57, 75, 32, 94, 59]
  Train samples: 5000
  Test samples: 1000
Task 8: Classes [63, 84, 37, 29, 1, 52, 21, 2, 23, 87]
  Train samples: 5000
  Test samples: 1000
Task 9: Classes [91, 74, 86, 82, 20, 60, 71, 14, 92, 51]
  Train samples: 5000
  Test samples: 1000
Task 0: Classes [83, 53, 70, 45, 44, 39, 22, 80, 10, 0]
  Train samples: 5000
  Test samples: 1000
Evaluating on Task 0 (Classes: [83, 53, 70, 45, 44, 39, 22, 80, 10, 0])...
Task 0 Accuracy: 0.0000
Task 1: Classes [18, 30, 73, 33, 90, 4, 76, 77, 12, 31]
  Train samples: 5000
  Test samples: 1000
Evaluating on Task 1 (Classes: [18, 30, 73, 33, 90, 4, 76, 77, 12, 31])...
Task 1 Accuracy: 0.0000
Task 2: Classes [55, 88, 26, 42, 69, 15, 40, 96, 9, 72]
  Train samples: 5000
  Test samples: 1000
Evaluating on Task 2 (Classes: [55, 88, 26, 42, 69, 15, 40, 96, 9, 72])...
Task 2 Accuracy: 0.0000
Task 3: Classes [11, 47, 85, 28, 93, 5, 66, 65, 35, 16]
  Train samples: 5000
  Test samples: 1000
Evaluating on Task 3 (Classes: [11, 47, 85, 28, 93, 5, 66, 65, 35, 16])...
Task 3 Accuracy: 0.0000
Task 4: Classes [49, 34, 7, 95, 27, 19, 81, 25, 62, 13]
  Train samples: 5000
  Test samples: 1000
Evaluating on Task 4 (Classes: [49, 34, 7, 95, 27, 19, 81, 25, 62, 13])...
Task 4 Accuracy: 0.0000
Task 5: Classes [24, 3, 17, 38, 8, 78, 6, 64, 36, 89]
  Train samples: 5000
  Test samples: 1000
Evaluating on Task 5 (Classes: [24, 3, 17, 38, 8, 78, 6, 64, 36, 89])...
Task 5 Accuracy: 0.0000
Task 6: Classes [56, 99, 54, 43, 50, 67, 46, 68, 61, 97]
  Train samples: 5000
  Test samples: 1000
Evaluating on Task 6 (Classes: [56, 99, 54, 43, 50, 67, 46, 68, 61, 97])...
Task 6 Accuracy: 0.0000
Task 7: Classes [79, 41, 58, 48, 98, 57, 75, 32, 94, 59]
  Train samples: 5000
  Test samples: 1000
Evaluating on Task 7 (Classes: [79, 41, 58, 48, 98, 57, 75, 32, 94, 59])...
Task 7 Accuracy: 0.0000
Task 8: Classes [63, 84, 37, 29, 1, 52, 21, 2, 23, 87]
  Train samples: 5000
  Test samples: 1000
Evaluating on Task 8 (Classes: [63, 84, 37, 29, 1, 52, 21, 2, 23, 87])...
Task 8 Accuracy: 0.0000
Task 9: Classes [91, 74, 86, 82, 20, 60, 71, 14, 92, 51]
  Train samples: 5000
  Test samples: 1000
Evaluating on Task 9 (Classes: [91, 74, 86, 82, 20, 60, 71, 14, 92, 51])...
Task 9 Accuracy: 0.6980

============================================================
Final Accuracies: ['0.0000', '0.0000', '0.0000', '0.0000', '0.0000', '0.0000', '0.0000', '0.0000', '0.0000', '0.6980']
Average Accuracy: 0.0698
Final Task: 0.6980
Early Tasks Avg: 0.0000
============================================================
Results saved to results_resnet_cifar100/lambda_sweep/lambda_1000_results.json

[5/7] Training λ=2000...
/Users/sunilkumars/Desktop/EWC Project/drift_cl_edge/venv/lib/python3.13/site-packages/torchvision/datasets/cifar.py:83: VisibleDeprecationWarning: dtype(): align should be passed as Python or NumPy boolean but got `align=0`. Did you mean to pass a tuple to create a subarray type? (Deprecated NumPy 2.4)
  entry = pickle.load(f, encoding="latin1")
/Users/sunilkumars/Desktop/EWC Project/drift_cl_edge/venv/lib/python3.13/site-packages/torch/utils/data/dataloader.py:692: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, device pinned memory won't be used.
  warnings.warn(warn_msg)
Using device: mps
Training ResNet-18 on Split-CIFAR-100: 10 tasks, 10 epochs/task, λ=2000.0
Split-CIFAR-100 initialized:
  Tasks: 10
  Classes per task: 10
  Class order: [83 53 70 45 44 39 22 80 10  0 18 30 73 33 90  4 76 77 12 31]... (first 20)
Task 0: Classes [83, 53, 70, 45, 44, 39, 22, 80, 10, 0]
  Train samples: 5000
  Test samples: 1000
Task 1: Classes [18, 30, 73, 33, 90, 4, 76, 77, 12, 31]
  Train samples: 5000
  Test samples: 1000
Task 2: Classes [55, 88, 26, 42, 69, 15, 40, 96, 9, 72]
  Train samples: 5000
  Test samples: 1000
Task 3: Classes [11, 47, 85, 28, 93, 5, 66, 65, 35, 16]
  Train samples: 5000
  Test samples: 1000
Task 4: Classes [49, 34, 7, 95, 27, 19, 81, 25, 62, 13]
  Train samples: 5000
  Test samples: 1000
Task 5: Classes [24, 3, 17, 38, 8, 78, 6, 64, 36, 89]
  Train samples: 5000
  Test samples: 1000
Task 6: Classes [56, 99, 54, 43, 50, 67, 46, 68, 61, 97]
  Train samples: 5000
  Test samples: 1000
Task 7: Classes [79, 41, 58, 48, 98, 57, 75, 32, 94, 59]
  Train samples: 5000
  Test samples: 1000
Task 8: Classes [63, 84, 37, 29, 1, 52, 21, 2, 23, 87]
  Train samples: 5000
  Test samples: 1000
Task 9: Classes [91, 74, 86, 82, 20, 60, 71, 14, 92, 51]
  Train samples: 5000
  Test samples: 1000

============================================================
Training on Task 0 (Classes: [83, 53, 70, 45, 44, 39, 22, 80, 10, 0])
============================================================
Epoch 1/10 - Loss: 1.8882 - Acc: 0.3448
Epoch 2/10 - Loss: 1.4741 - Acc: 0.4556
Epoch 3/10 - Loss: 1.2961 - Acc: 0.5356
Epoch 4/10 - Loss: 1.1922 - Acc: 0.5734
Epoch 5/10 - Loss: 1.0319 - Acc: 0.6240
Epoch 6/10 - Loss: 0.9005 - Acc: 0.6856
Epoch 7/10 - Loss: 0.8153 - Acc: 0.7116
Epoch 8/10 - Loss: 0.7146 - Acc: 0.7534
Epoch 9/10 - Loss: 0.6295 - Acc: 0.7796
Epoch 10/10 - Loss: 0.5501 - Acc: 0.8010
Saved: results_resnet_cifar100/lambda_sweep/lambda_2000/model_task0.pt
Computing Fisher for Task 0...
Computing Fisher Matrix...
Fisher Matrix computed.

============================================================
Training on Task 1 (Classes: [18, 30, 73, 33, 90, 4, 76, 77, 12, 31])
============================================================
Epoch 1/10 - Loss: 3.4779 - Acc: 0.3362
Epoch 2/10 - Loss: 1.5161 - Acc: 0.5712
Epoch 3/10 - Loss: 1.2745 - Acc: 0.6644
Epoch 4/10 - Loss: 1.2069 - Acc: 0.7110
Epoch 5/10 - Loss: 1.2210 - Acc: 0.7386
Epoch 6/10 - Loss: 1.0363 - Acc: 0.7952
Epoch 7/10 - Loss: 1.4206 - Acc: 0.7362
Epoch 8/10 - Loss: 0.9327 - Acc: 0.8594
Epoch 9/10 - Loss: 0.6911 - Acc: 0.9150
Epoch 10/10 - Loss: 0.8325 - Acc: 0.8944
Saved: results_resnet_cifar100/lambda_sweep/lambda_2000/model_task1.pt
Computing Fisher for Task 1...
Computing Fisher Matrix...
Fisher Matrix computed.

============================================================
Training on Task 2 (Classes: [55, 88, 26, 42, 69, 15, 40, 96, 9, 72])
============================================================
Epoch 1/10 - Loss: 6.8983 - Acc: 0.2568
Epoch 2/10 - Loss: 2.2280 - Acc: 0.5430
Epoch 3/10 - Loss: 2.0035 - Acc: 0.6254
Epoch 4/10 - Loss: 2.0176 - Acc: 0.6566
Epoch 5/10 - Loss: 2.3165 - Acc: 0.6614
Epoch 6/10 - Loss: 1.9771 - Acc: 0.7432
Epoch 7/10 - Loss: 2.0303 - Acc: 0.7530
Epoch 8/10 - Loss: 2.1198 - Acc: 0.7770
Epoch 9/10 - Loss: 2.1637 - Acc: 0.7922
Epoch 10/10 - Loss: 1.6522 - Acc: 0.8738
Saved: results_resnet_cifar100/lambda_sweep/lambda_2000/model_task2.pt
Computing Fisher for Task 2...
Computing Fisher Matrix...
Fisher Matrix computed.

============================================================
Training on Task 3 (Classes: [11, 47, 85, 28, 93, 5, 66, 65, 35, 16])
============================================================
Epoch 1/10 - Loss: 11.6152 - Acc: 0.1488
Epoch 2/10 - Loss: 2.9477 - Acc: 0.5608
Epoch 3/10 - Loss: 2.8385 - Acc: 0.6250
Epoch 4/10 - Loss: 2.8921 - Acc: 0.6500
Epoch 5/10 - Loss: 2.7958 - Acc: 0.6848
Epoch 6/10 - Loss: 2.6585 - Acc: 0.7126
Epoch 7/10 - Loss: 2.7123 - Acc: 0.7372
Epoch 8/10 - Loss: 2.7923 - Acc: 0.7414
Epoch 9/10 - Loss: 2.7151 - Acc: 0.7736
Epoch 10/10 - Loss: 2.8933 - Acc: 0.7770
Saved: results_resnet_cifar100/lambda_sweep/lambda_2000/model_task3.pt
Computing Fisher for Task 3...
Computing Fisher Matrix...
Fisher Matrix computed.

============================================================
Training on Task 4 (Classes: [49, 34, 7, 95, 27, 19, 81, 25, 62, 13])
============================================================
Epoch 1/10 - Loss: 14.5356 - Acc: 0.1094
Epoch 2/10 - Loss: 3.2259 - Acc: 0.5732
Epoch 3/10 - Loss: 2.8938 - Acc: 0.6574
Epoch 4/10 - Loss: 3.0234 - Acc: 0.6786
Epoch 5/10 - Loss: 2.6668 - Acc: 0.7264
Epoch 6/10 - Loss: 2.7376 - Acc: 0.7418
Epoch 7/10 - Loss: 2.9121 - Acc: 0.7234
Epoch 8/10 - Loss: 2.6421 - Acc: 0.7698
Epoch 9/10 - Loss: 2.7302 - Acc: 0.7760
Epoch 10/10 - Loss: 3.1496 - Acc: 0.7548
Saved: results_resnet_cifar100/lambda_sweep/lambda_2000/model_task4.pt
Computing Fisher for Task 4...
Computing Fisher Matrix...
Fisher Matrix computed.

============================================================
Training on Task 5 (Classes: [24, 3, 17, 38, 8, 78, 6, 64, 36, 89])
============================================================
Epoch 1/10 - Loss: 18.2293 - Acc: 0.0490
Epoch 2/10 - Loss: 3.7902 - Acc: 0.5054
Epoch 3/10 - Loss: 3.2071 - Acc: 0.6384
Epoch 4/10 - Loss: 3.1737 - Acc: 0.6638
Epoch 5/10 - Loss: 3.2804 - Acc: 0.6660
Epoch 6/10 - Loss: 3.1508 - Acc: 0.6882
Epoch 7/10 - Loss: 3.2956 - Acc: 0.6834
Epoch 8/10 - Loss: 3.3145 - Acc: 0.6920
Epoch 9/10 - Loss: 3.1481 - Acc: 0.7208
Epoch 10/10 - Loss: 3.2828 - Acc: 0.7208
Saved: results_resnet_cifar100/lambda_sweep/lambda_2000/model_task5.pt
Computing Fisher for Task 5...
Computing Fisher Matrix...
Fisher Matrix computed.

============================================================
Training on Task 6 (Classes: [56, 99, 54, 43, 50, 67, 46, 68, 61, 97])
============================================================
Epoch 1/10 - Loss: 21.3982 - Acc: 0.0254
Epoch 2/10 - Loss: 5.1363 - Acc: 0.3502
Epoch 3/10 - Loss: 3.5613 - Acc: 0.6402
Epoch 4/10 - Loss: 3.2791 - Acc: 0.6986
Epoch 5/10 - Loss: 3.2463 - Acc: 0.6966
Epoch 6/10 - Loss: 3.4647 - Acc: 0.7008
Epoch 7/10 - Loss: 3.1226 - Acc: 0.7240
Epoch 8/10 - Loss: 3.4894 - Acc: 0.7244
Epoch 9/10 - Loss: 3.2594 - Acc: 0.7266
Epoch 10/10 - Loss: 3.3371 - Acc: 0.7192
Saved: results_resnet_cifar100/lambda_sweep/lambda_2000/model_task6.pt
Computing Fisher for Task 6...
Computing Fisher Matrix...
Fisher Matrix computed.

============================================================
Training on Task 7 (Classes: [79, 41, 58, 48, 98, 57, 75, 32, 94, 59])
============================================================
Epoch 1/10 - Loss: 28.2311 - Acc: 0.0002
Epoch 2/10 - Loss: 6.3301 - Acc: 0.3344
Epoch 3/10 - Loss: 3.3739 - Acc: 0.6872
Epoch 4/10 - Loss: 3.2364 - Acc: 0.7398
Epoch 5/10 - Loss: 3.3272 - Acc: 0.7388
Epoch 6/10 - Loss: 3.1793 - Acc: 0.7536
Epoch 7/10 - Loss: 3.0027 - Acc: 0.7838
Epoch 8/10 - Loss: 3.1782 - Acc: 0.7712
Epoch 9/10 - Loss: 3.1873 - Acc: 0.7704
Epoch 10/10 - Loss: 3.0107 - Acc: 0.7884
Saved: results_resnet_cifar100/lambda_sweep/lambda_2000/model_task7.pt
Computing Fisher for Task 7...
Computing Fisher Matrix...
Fisher Matrix computed.

============================================================
Training on Task 8 (Classes: [63, 84, 37, 29, 1, 52, 21, 2, 23, 87])
============================================================
Epoch 1/10 - Loss: 27.9930 - Acc: 0.0046
Epoch 2/10 - Loss: 7.8412 - Acc: 0.1928
Epoch 3/10 - Loss: 3.8536 - Acc: 0.6530
Epoch 4/10 - Loss: 3.5930 - Acc: 0.7118
Epoch 5/10 - Loss: 3.3339 - Acc: 0.7402
Epoch 6/10 - Loss: 3.3234 - Acc: 0.7406
Epoch 7/10 - Loss: 3.4867 - Acc: 0.7264
Epoch 8/10 - Loss: 3.4086 - Acc: 0.7344
Epoch 9/10 - Loss: 3.1321 - Acc: 0.7662
Epoch 10/10 - Loss: 3.4037 - Acc: 0.7580
Saved: results_resnet_cifar100/lambda_sweep/lambda_2000/model_task8.pt
Computing Fisher for Task 8...
Computing Fisher Matrix...
Fisher Matrix computed.

============================================================
Training on Task 9 (Classes: [91, 74, 86, 82, 20, 60, 71, 14, 92, 51])
============================================================
Epoch 1/10 - Loss: 30.9901 - Acc: 0.0008
Epoch 2/10 - Loss: 10.5346 - Acc: 0.1054
Python(8590) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.
Python(8593) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.
Epoch 3/10 - Loss: 5.1629 - Acc: 0.4986
Python(9580) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.
Python(9694) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.
Epoch 4/10 - Loss: 3.5691 - Acc: 0.6854
Python(10930) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.
Python(11047) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.
Epoch 5/10 - Loss: 3.6194 - Acc: 0.6962
Python(11466) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.
Python(11773) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.
Epoch 6/10 - Loss: 3.3766 - Acc: 0.7340
Python(12531) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.
Python(12536) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.
Epoch 7/10 - Loss: 3.3957 - Acc: 0.7296
Python(13042) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.
Python(13151) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.
Epoch 8/10 - Loss: 3.5809 - Acc: 0.7244
Python(14692) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.
Python(14809) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.
